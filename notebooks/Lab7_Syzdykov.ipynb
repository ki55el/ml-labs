{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl014JBMqBEJ"
      },
      "source": [
        "# Лабораторная работа №7. \"Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5U3gQAyqb6s"
      },
      "source": [
        "## Задание №1.\n",
        "Решить задачи регрессии и классификации на данных в соответствии с Вашим индивидуальным вариантом (см. Лаб.работы №3, 4), используя полносвязные НС; реализовать НС посредством API Keras и фреймворка TensorFlow; оценить качество полученных моделей с помощью метрик."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Be7lurjLq47i"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import warnings\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def metrics_c(actual, pred):\n",
        "  return {\n",
        "    'Accuracy': accuracy_score(actual, pred),\n",
        "    'Precision': precision_score(actual, pred),\n",
        "    'Recall': recall_score(actual, pred),\n",
        "    'F1-score': f1_score(actual, pred),\n",
        "    'ROC_AUC': roc_auc_score(actual, pred)\n",
        "  }\n",
        "models_c = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "def metrics_r(actual, pred):\n",
        "  return {\n",
        "    'MAE': mean_absolute_error(actual, pred),\n",
        "    'MSE': mean_squared_error(actual, pred),\n",
        "    'RMSE': sqrt(mean_squared_error(actual, pred)),\n",
        "    'MAPE': mean_absolute_percentage_error(actual, pred),\n",
        "    'R^2': r2_score(actual, pred)\n",
        "  }\n",
        "models_r = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_model(models, metrics):\n",
        "    return max([(val[metrics], k) for k, val in models.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfc = pd.read_csv('../data/neo_task_upd.csv')[:5561]\n",
        "yc = dfc['hazardous']\n",
        "Xc = dfc.drop(['hazardous'], axis=1)\n",
        "\n",
        "smote = SMOTE()\n",
        "Xc, yc = smote.fit_resample(Xc, yc)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "Xc = scaler.fit_transform(Xc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfr = pd.read_csv('../data/energy_task_upd.csv', parse_dates=['date']).set_index('date')\n",
        "yr = dfr['Appliances']\n",
        "Xr = dfr.drop(['Appliances'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2)\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((9880, 28), (9980, 5))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xr.shape, Xc.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                1856      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4481 (17.50 KB)\n",
            "Trainable params: 4481 (17.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# создаем модель, как набор последовательных слоев\n",
        "model_regression = tf.keras.Sequential(\n",
        "    [\n",
        "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(28,)),\n",
        "        # на втором скрытом слое будет 32 нейрона\n",
        "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
        "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
        "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        # на выходе один нейрон, функция активации не применяется\n",
        "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_regression.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "247/247 [==============================] - 1s 2ms/step - loss: 463.0672\n",
            "Epoch 2/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.9760\n",
            "Epoch 3/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.6210\n",
            "Epoch 4/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 463.2468\n",
            "Epoch 5/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 464.3595\n",
            "Epoch 6/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 462.0815\n",
            "Epoch 7/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 451.9352\n",
            "Epoch 8/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.0807\n",
            "Epoch 9/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.7115\n",
            "Epoch 10/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.2635\n",
            "Epoch 11/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.0978\n",
            "Epoch 12/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.7654\n",
            "Epoch 13/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.6057\n",
            "Epoch 14/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.7857\n",
            "Epoch 15/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.1735\n",
            "Epoch 16/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.9979\n",
            "Epoch 17/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.0016\n",
            "Epoch 18/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.8041\n",
            "Epoch 19/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 464.3170\n",
            "Epoch 20/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.6626\n",
            "Epoch 21/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.8784\n",
            "Epoch 22/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 451.0372\n",
            "Epoch 23/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.2558\n",
            "Epoch 24/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 462.6510\n",
            "Epoch 25/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 450.9209\n",
            "Epoch 26/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.4074\n",
            "Epoch 27/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.2273\n",
            "Epoch 28/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.8961\n",
            "Epoch 29/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 462.6336\n",
            "Epoch 30/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 461.0585\n",
            "Epoch 31/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.7501\n",
            "Epoch 32/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 461.7450\n",
            "Epoch 33/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.3293\n",
            "Epoch 34/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.9626\n",
            "Epoch 35/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 470.3408\n",
            "Epoch 36/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.3997\n",
            "Epoch 37/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.1935\n",
            "Epoch 38/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.8208\n",
            "Epoch 39/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.7937\n",
            "Epoch 40/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.7155\n",
            "Epoch 41/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 466.6986\n",
            "Epoch 42/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.6174\n",
            "Epoch 43/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 453.6513\n",
            "Epoch 44/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 453.9658\n",
            "Epoch 45/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.9715\n",
            "Epoch 46/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.9329\n",
            "Epoch 47/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.8351\n",
            "Epoch 48/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.5916\n",
            "Epoch 49/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.3557\n",
            "Epoch 50/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 464.8404\n",
            "Epoch 51/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.4974\n",
            "Epoch 52/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.3041\n",
            "Epoch 53/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 448.3578\n",
            "Epoch 54/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.8983\n",
            "Epoch 55/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.0066\n",
            "Epoch 56/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 461.9719\n",
            "Epoch 57/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.6204\n",
            "Epoch 58/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 461.7855\n",
            "Epoch 59/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 461.4856\n",
            "Epoch 60/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.4488\n",
            "Epoch 61/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.2404\n",
            "Epoch 62/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.2011\n",
            "Epoch 63/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.2580\n",
            "Epoch 64/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.7887\n",
            "Epoch 65/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.0768\n",
            "Epoch 66/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.0072\n",
            "Epoch 67/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.6966\n",
            "Epoch 68/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.5396\n",
            "Epoch 69/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.4362\n",
            "Epoch 70/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 450.8621\n",
            "Epoch 71/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.0654\n",
            "Epoch 72/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 465.5457\n",
            "Epoch 73/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.4462\n",
            "Epoch 74/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.8780\n",
            "Epoch 75/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.3232\n",
            "Epoch 76/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 451.6913\n",
            "Epoch 77/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 453.8977\n",
            "Epoch 78/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.3255\n",
            "Epoch 79/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 451.5956\n",
            "Epoch 80/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.8970\n",
            "Epoch 81/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.4020\n",
            "Epoch 82/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 449.7729\n",
            "Epoch 83/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 451.4177\n",
            "Epoch 84/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.6390\n",
            "Epoch 85/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 462.1140\n",
            "Epoch 86/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.9731\n",
            "Epoch 87/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.3958\n",
            "Epoch 88/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.4673\n",
            "Epoch 89/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.0159\n",
            "Epoch 90/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.6818\n",
            "Epoch 91/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 453.5006\n",
            "Epoch 92/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.3709\n",
            "Epoch 93/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.7359\n",
            "Epoch 94/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.3824\n",
            "Epoch 95/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.1809\n",
            "Epoch 96/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 448.5991\n",
            "Epoch 97/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 464.6234\n",
            "Epoch 98/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.4332\n",
            "Epoch 99/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.0361\n",
            "Epoch 100/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.4594\n",
            "Epoch 101/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 454.9155\n",
            "Epoch 102/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 451.9476\n",
            "Epoch 103/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 450.5552\n",
            "Epoch 104/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.4888\n",
            "Epoch 105/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 460.7059\n",
            "Epoch 106/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 459.5720\n",
            "Epoch 107/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.0114\n",
            "Epoch 108/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 456.9956\n",
            "Epoch 109/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 461.4405\n",
            "Epoch 110/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 453.9880\n",
            "Epoch 111/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.8011\n",
            "Epoch 112/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 450.1096\n",
            "Epoch 113/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 458.6731\n",
            "Epoch 114/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.3658\n",
            "Epoch 115/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 457.8300\n",
            "Epoch 116/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 453.0029\n",
            "Epoch 117/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 455.0052\n",
            "Epoch 118/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 449.5902\n",
            "Epoch 119/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 466.3522\n",
            "Epoch 120/120\n",
            "247/247 [==============================] - 0s 2ms/step - loss: 452.7025\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x23267cab210>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")\n",
        "\n",
        "model_regression.fit(Xr_train, yr_train, epochs=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'MAE': 13.995576781299915,\n",
              " 'MSE': 413.8410771754459,\n",
              " 'RMSE': 20.343084259163994,\n",
              " 'MAPE': 0.2492361631347352,\n",
              " 'R^2': 0.32692265827417855}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_r(yr_test, model_regression.predict(Xr_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Класификация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\User\\ml-labs\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\User\\ml-labs\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_classification_1 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(5,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # сначала используем 1 нейрон и sigmoid\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "# в качестве функции активации используется бинарная  кроссэнтропия\n",
        "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "# verbose=None - не будет логов\n",
        "model_classification_1.fit(Xc_train, yc_train, epochs=25, verbose=None)\n",
        "\n",
        "model_classification_1.predict(Xc_test, verbose=None)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1001\n",
            "           1       0.50      1.00      0.67       995\n",
            "\n",
            "    accuracy                           0.50      1996\n",
            "   macro avg       0.25      0.50      0.33      1996\n",
            "weighted avg       0.25      0.50      0.33      1996\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[   0, 1001],\n",
              "       [   0,  995]], dtype=int64)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yc_pred = np.around(model_classification_1.predict(Xc_test, verbose=None))\n",
        "\n",
        "print(classification_report(yc_test, yc_pred))\n",
        "confusion_matrix(yc_test, yc_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w0 = 1 / yc_train[yc_train==0].shape[0]\n",
        "w1 = 1 / yc_train[yc_train==1].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.02      0.04      1001\n",
            "           1       0.50      1.00      0.67       995\n",
            "\n",
            "    accuracy                           0.51      1996\n",
            "   macro avg       0.67      0.51      0.36      1996\n",
            "weighted avg       0.68      0.51      0.35      1996\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 22, 979],\n",
              "       [  4, 991]], dtype=int64)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_1 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(5,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # используем 1 нейрон и sigmoid\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
        "model_classification_1.fit(Xc_train, yc_train, epochs=25, verbose=None, class_weight={0: w0, 1: w1})\n",
        "yc_pred = np.around(model_classification_1.predict(Xc_test, verbose=None))\n",
        "\n",
        "print(classification_report(yc_test, yc_pred))\n",
        "confusion_matrix(yc_test, yc_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5062273 , 0.49377263],\n",
              "       [0.5062273 , 0.49377263],\n",
              "       [0.5062273 , 0.49377263],\n",
              "       [0.5062273 , 0.49377263],\n",
              "       [0.5062273 , 0.49377263]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classification_2 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(5,)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # сначала используем 2 нейрона и softmax\n",
        "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "# в качестве функции активации используется категориальная кроссэнтропия\n",
        "# используем разряженный (sparse) вариант, поскольку значения целевого признака не закодированы One-Hot кодированием\n",
        "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
        "model_classification_2.fit(Xc_train, yc_train, epochs=25, verbose=None, class_weight={0: w0, 1: w1})\n",
        "\n",
        "model_classification_2.predict(Xc_test, verbose=None)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# получим индексы максимального значения для каждого элемента (вложенный массив) с помощью numpy\n",
        "yc_pred = [np.argmax(pred) for pred in model_classification_2.predict(Xc_test, verbose=None)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.68      1033\n",
            "           1       0.00      0.00      0.00       963\n",
            "\n",
            "    accuracy                           0.52      1996\n",
            "   macro avg       0.26      0.50      0.34      1996\n",
            "weighted avg       0.27      0.52      0.35      1996\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1033,    0],\n",
              "       [ 963,    0]], dtype=int64)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(classification_report(yc_test, yc_pred))\n",
        "confusion_matrix(yc_test, yc_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuL7MpCOqb-B"
      },
      "source": [
        "## Задание №2.\n",
        "Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации. Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu; также предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой. Реализовать обучение MLP методом обратного распространения ошибки; самостоятельно найти производные функций sigmoid, tanh и relu; реализовать классический градиентный спуск с возможностью указания шага."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbf1KXatqBHe"
      },
      "source": [
        "## Дополнительное Задание №3*.\n",
        "1. Самостоятельно изучить отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска.\n",
        "2. Реализовать градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптими-заторов в Вашем персептроне."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
